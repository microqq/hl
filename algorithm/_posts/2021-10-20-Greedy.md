---
layout: post
title:  "贪心法"
date:   2021-10-20
categories: 
    - algorithm
---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

贪心算法

- [1. 贪心法是什么？](#1-贪心法是什么)
- [2. 它解决什么问题？](#2-它解决什么问题)
  - [2.1 最优化问题](#21-最优化问题)
  - [2.2 基本步骤](#22-基本步骤)
  - [2.3. 贪心法关键要素](#23-贪心法关键要素)
- [3. 经典例题](#3-经典例题)
  - [3.1 霍夫曼编码](#31-霍夫曼编码)
    - [3.1.1 贪心选择性质](#311-贪心选择性质)
    - [3.1.2 最优子结构](#312-最优子结构)
    - [3.1.3 代码实现](#313-代码实现)
  - [3.2 跳跃游戏](#32-跳跃游戏)
- [参考](#参考)

#### 1. 贪心法是什么？

贪心法是什么？贪心法是一种解决**某些**最优化问题的方法，它是一种当前的“短视”选择，不需要从整体考虑，**每一步(或每一个子问题)** 所做的选择只是在当前看来是最优选择，藉此**希望**（不能保证一定能够获得整体或全局最优解）能够获得整体（或全局）的最优解。

#### 2. 它解决什么问题？

##### 2.1 最优化问题

贪心法通常用来求解某些“最优化问题”。

“最优化问题”指的是在一定的**约束条件**下，求解**目标函数**的**最大值**（或**最小值**）的问题。它的数学表达是：给定一个函数${\displaystyle f:A\to \mathbb {R}}$ ，**寻找**一个元素${\displaystyle \mathbf {x} ^{0}\in A}$（$\mathbf {x} ^{0}\in A$ 满足约束条件） 使得对于所有 ${\displaystyle A}$ 中的 ${\displaystyle \mathbf {x}}$，${\displaystyle f(\mathbf {x} ^{0})\leq f(\mathbf {x} )}$（最小化）；或者 ${\displaystyle f(\mathbf {x} ^{0})\geq f(\mathbf {x} )}$（最大化）[<sup>[1]</sup>](#refer-anchor-1)。

典型的，${\displaystyle A}$一般为欧几里得空间${\displaystyle \mathbb {R} ^{n}}$中的子集，通常由一个${\displaystyle A}$必须满足的约束等式或者不等式来规定。 ${\displaystyle A}$的元素被称为是可行解。函数${\displaystyle f}$被称为目标函数，或者代价函数。一个最小化（或者最大化）目标函数的可行解被称为最优解[<sup>[1]</sup>](#refer-anchor-1)。

##### 2.2 基本步骤

贪心法求解“最优化问题”**基本步骤**[<sup>[1]</sup>](#refer-anchor-1)，

1. 建立数学模型来描述问题，也就是确定**约束条件**，**目标函数**的数学表达；
2. 问题分解，将原问题分解成若干的子问题；
3. 对每一子问题求解，做出局部最优选择（贪心选择），得到局部最优解（可行解元素）；
4. 把局部最优解合成原问题的整体最优解。

##### 2.3. 贪心法关键要素

贪心法并不可能适用与所有的情况，如何证明贪心法能否求解一个最优化问题？

贪心法求解最优化问题有两个**关键要素：贪心选择性质和最优子结构**。

- 贪心选择性质

与动态规划方法一样，我们将原问题分解成子问题，不同之处在于，动态规划的决策状态会影响到后续决策选择，也就是说某一步的决策状态受它之前的决策状态影响，换句话说，**动态规划的决策通常依赖于子问题的决策（解），而贪心法在做出选择时，只做出在当前问题看来的最优选择，而不考虑子问题的选择(解)**。通常动态规划、分治法都是自底向上分解问题，而贪心法则是自顶向下分解问题。

- 最优子结构

贪心算法在有最优子结构的问题中尤为有效。最优子结构的意思是局部最优解能决定全局最优解。简单地说，问题能够分解成子问题来解决，子问题的最优解能递推到最终问题的最优解[<sup>[1]</sup>](#refer-anchor-1)，反过来，我们可以说：**如果一个问题的最优解包含其子问题的最优解，那么称该问题具有最优子结构性质**。

证明这两条性质，就可以证明贪心法能够得到最优解。

#### 3. 经典例题

##### 3.1 霍夫曼编码

霍夫曼编码是一种**变长编码**，用较少的比特表示出现频率高的字符，用较多的比特表示出现频率低的字符。但是**变长编码**如果没有分隔符，容易产生歧义，因此，霍夫曼编码采用了**前缀码**表示。

**前缀码**指的是字符集编码时，其中任意一个字符的编码都不是其他任意一个字符编码的**前缀**。**平均码长或者总长最小的前缀码称为最优前缀码**，霍夫曼编码就是一种最优前缀码。

**任一的编码方案都可以描述为一棵二叉树**，叶子节点表示字符，字符的二进制编码用根节点到该字符的叶节点路径表示，其中 $0$ 表示转向左孩子，而 $1$ 则表示转向右孩子。

最优的编码方案一定是一棵**满二叉树**——即非叶子节点一定有两个孩子节点，反过来，则满二叉树不一定是最优编码方案。但是**非满二叉树**一定不是最优编码方案，假设现在有一棵**非满二叉树** $T$ 是一个最优的编码方案，$T$ 是非满二叉树，因此一定有非叶子节点 $N_i$ 仅有左孩子或者右孩子，将 $N_i$ 节点删除，用其左孩子或者右孩子节点代替，那么原来 $N_i$ 节点所有的子孙节点编码长度比原来少 $1$，因此**非满二叉树**一定不是最优的编码方案。

###### 3.1.1 贪心选择性质

贪心法不一定能够求解得到“最优化问题”的最优解，需要证明每一步（或每一个子问题）的选择（或决策）求解的局部最优解合并后，能够取得原问题的整体（或全局）最优解。

我们要证明：为什么选择频率最低的两个节点结为兄弟节点可以得到最优前缀码？

我们以 $C$ 表示字母表，对于其中每个字符 $c$，$c.freq$ 表示字符的出现频率，假设字符 $c_1、c_2$ 是字母表 $C$ 中频率最低的两个字符，我们要证明：**如果存在 $C$ 对应的最优前缀码，那么该前缀码中对应的字符 $c_1、c_2$ 的编码码字长度相同，且只有最后一个二进制位不同**，意味着最优前缀码中，频率最低的两个两个字符一定在深度最大的叶子节点上，且互为兄弟。

- 替换论证法

证明的思路是假设最优前缀码对应的二叉树 $T$，$a$ 和 $b$ 表示 $T$ 中深度最大的两个叶子节点对应字符，如果我们用 $c_1$ 和 $c_2$ 替换 $a$ 和 $b$，仍然能够使得新的二叉树 $T_1$ 也是**最优二叉树**，那么贪心选择性质得证。

令 $d_T(c)$ 表示 $c$ 对应叶子节点的深度，那么字母表 $C$ 编码需要：

$$
B(T) = \sum_{c\in{C}} c.freq \cdot {d_T(c)}.
$$

$B(T)$ 表示字母表编码代价。

假设 $a.freq \leq b.freq$，且 $c_1.freq \leq c_2.freq$，因为 $c_1$ 和 $c_2$ 是字母表中频率最低的两个字符，所以，$a.freq \leq c_1.freq$，且 $b.freq \leq c_2.freq$。

我们将 $s_1、s_2$ 替换 $a、b$ 得到二叉树 $T_1$，由上面条件可得：

$$
B(T) \geq B(T_1)
$$

编码代价变低了，因此 $T_1$ 也是最优二叉树，贪心选择性质得证。

###### 3.1.2 最优子结构

假设$T$ 是字母表 $T$ 对应最优前缀码的最优二叉树，令 $C^{'}$ 是字母表 $C$ 去掉字符 $c_1、c_2$ 后，加入一个新字符 $c_p$ 的字母表，$T^{'} 是对应的最优前缀码的最优二叉树，$ $c_{p}$ 是 $c_1、c_2$ 的父节点，其深度 $d_{T^{'}}(c_{p}) = d_T(c_1) - 1 = d_T(c_1) - 1$，$c_p.freq = c_1.freq + c_2.freq$，$B(T^{'})$ 代价为：

$$
B(T^{'}) = B(T) - c_1.freq - c_2.freq.
$$

回顾一下最优子结构的定义：**如果一个问题的最优解包含其子问题的最优解，那么称该问题有最优子结构**，也就是说我们可以由子问题的最优解，合并得到原问题的最优解。那么，当 $T^{'}$ 是最优二叉树时，我们需要证明 $T$ 也是最优二叉树。我们采用反证法来证明：

假设 $T$ 不是字母表 $C$ 的最优二叉树，$T_1$ 是包含字符 $c_1、c_2$ 的字母表 $C$ 最优二叉树，所以，$B(T_1) < B(T)$，$T_2$ 是去掉字符 $c_1、c_2$，并加入 $c_p$ 的字母表 $C^{'}$ 的最优二叉树，$T_1$ 和 $T_2$ 关系表示如下：

$$
\begin{aligned}
& B(T_1) < B(T) \\
& B(T_2) = B(T_1) - c_1.freq - c_2.freq < B(T) - c_1.freq - c_2.freq \\
\end{aligned}
$$

这样 $B(T_2) < B(T^{'})$，而实际上我们假设了 $T{'}$ 也是最优二叉树，应该 $B(T_2) = B(T^{'})$，所以与假设相矛盾，$T$ 必然也是最优二叉树。

###### 3.1.3 代码实现

假设有字母表 $C$，我们要构造一棵最优二叉树：自底向上，每一次从字母表中取得频率最低的两个字符生成兄弟叶子节点，父节点频率为孩子节点频率之和。

```
HUFFMAN(C)
n = |C|
// Q:优先队列
Q = C
for i=0 to n
  // 从优先队列中提取频率最低的节点，并生成它们的父节点
  parent.left = c1 = EXTRACT-MIN(Q)
  parent.right = c2 = EXTRACT-MIN(Q)
  parent.freq = c1.freq + c2.freq

  // 将新生成的父节点插入优先队列
  INERSET-TO-Q(parent)

// 返回最优二叉树
return EXTRACT-MIN(Q)
```

##### 3.2 跳跃游戏

#### 参考

<div id="refer-anchor-1"></div>

[1] [贪心算法-维基百科](https://zh.wikipedia.org/wiki/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95)

<div id="refer-anchor-2"></div>

[2] [最优化-维基百科](https://zh.wikipedia.org/wiki/%E6%9C%80%E4%BC%98%E5%8C%96)

<div id="refer-anchor-3"></div>

[3] 算法导论, 第三版, P423